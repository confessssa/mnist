import tensorflow as tf
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession
config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()
print("Image labels example: ", y_train[:20])
import numpy as np

from tensorflow.keras.utils import to_categorical as to_categ

y_onehot = to_categ(y_train[:15], 10)
for ylb, yoh in zip(y_train[:15], y_onehot):
    print(ylb, yoh)

import matplotlib.pyplot as plt

fig, axs = plt.subplots(nrows=10, ncols=16)

for ax, X, y in zip(axs.reshape(-1), X_train, y_train):
    ax.imshow(X, cmap='gray_r')
    ax.axis("off")
    
plt.tight_layout()

import matplotlib.pyplot as plt

fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))

axs[0].hist(y_train, bins=10, rwidth=0.8)
axs[1].hist(y_test, bins=10, rwidth=0.8);

input_shape = X_train.shape[1:]

model_mnist = tf.keras.models.Sequential([
    tf.keras.layers.Lambda(lambda data: data / 256.0, input_shape=input_shape),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(10, activation='relu'),
    tf.keras.layers.Dense(30, activation='relu'),
    tf.keras.layers.Dense(50, activation='relu'),
    tf.keras.layers.Dense(30, activation='relu'),
    tf.keras.layers.Dense(10) 
])

model_mnist.compile(optimizer=tf.keras.optimizers.Adam(),  
                      loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
                      metrics=['accuracy'])

model_mnist.summary()

hist_mnist = model_mnist.fit(X_train, to_categ(y_train), epochs=50, validation_split=0.2, verbose=2)

import matplotlib.pyplot as plt

def plot_hist_one(hist, name, axs):
    """Plot one loss and accuracy"""
    epochs = len(hist.history['loss'])
    xs = list(range(epochs))
    
    ax = axs[0]
    ax.plot(xs, hist.history['loss'], label='loss')
    ax.plot(xs, hist.history['val_loss'], label='val_loss')
    ax.set_ylabel('loss')
    ax.set_yscale('log')

    ax = axs[1]
    ax.plot(xs, hist.history['accuracy'], label='accuracy');
    ax.plot(xs, hist.history['val_accuracy'], label='val_accuracy');
    ax.set_ylabel('accuracy')

    for ax in axs:
        ax.grid()
        ax.set_xlabel('epoch')
        ax.legend(title=name)    

def plot_hist(hist_list, hist_names):
    """Plot loss and accuracy for many network"""
    N = len(hist_list)
    fig, axs = plt.subplots(nrows=N, ncols=2, figsize=(10, 3*N))
    if N == 1:
        axs = [axs]
    for hist, name, ax in zip(hist_list, hist_names, axs):
        plot_hist_one(hist, name, ax)
    plt.tight_layout()

plot_hist([hist_mnist], ["mnist"])
acc, loss = model_mnist.evaluate(X_test, to_categ(y_test))
print(f"acc={acc}, loss={loss}")

y_logits = model_mnist(X_test, training=False)
print(y_logits[:3])

y_pred = tf.math.argmax(y_logits, axis=1).numpy()
print(y_pred[:3])

fig, axs = plt.subplots(nrows=8, ncols=8, figsize=(10, 10))

for ax, X, y in zip(axs.ravel(), X_test, y_pred):
    ax.imshow(X, cmap='gray_r')
    ax.set_title(f"{y}")
    ax.axis("off")
    
plt.tight_layout()